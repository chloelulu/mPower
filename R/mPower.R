#' @title A Real Data-based Power Analysis Tool for Microbiome Study Design
#' @description This function estimates the power for microbiome study design based on various experimental designs and parameters.
#' @param feature.dat data frame where taxa are in rows and samples are in columns.
#' @param model.paras list of model parameters output from the \code{EstPara} function.
#' @param test should be "Taxa" or "Community", indicating estimate taxa-level power or community-level power.
#' @param design the experimental design should be "CaseControl" or "CrossSectional" or "MatchedPair".
#' @param nSams an integer or a vector of integers, indicating the number of samples or subjects for power estimate.
#' @param grp.ratio a value between 0 and 1, only need to be supplied for "CaseControl" design. i.e., group ratio=0.6 (60/(60+40)=0.6) for 100 samples means comparing group1: 60 vs group2: 40.
#' @param iters the number of iterations for simulating microbiome data for power estimation. Community-level test: at least 500; Taxon-level test: at least 50.
#' @param alpha a value between 0 and 1 indicating the significance level for detecting differential taxa. Alpha in community-level test: this is the probability of rejecting the null hypothesis when it is true. The significance level is typically set at 0.05, meaning that there is a 5 percent chance we would reject the null hypothesis when it's true. Alpha in taxon-level test: False discovery rate(FDR), the expected proportion of non-differential taxa in the discovery. A typical FDR level can be 5 percent or 10 percent.
#' @param distance the type of distance metric used in community-level power estimation: "BC" or "Jaccard". Should be ignored for Taxa-level power estimation. Jaccard distance assesses community similarity by species presence or absence; Bray-Curtis (BC) distance considers both presence and species abundance.
#' @param diff.otu.pct a numeric value between 0 and 1 indicating the percentage of differential taxa to be estimated. If 0, global null setting is simulated. The default is 0.1.
#' @param diff.otu.direct should be "balanced" or "unbalanced". "balanced": the direction of change for these differential taxa is random, "unbalanced": direction of change is the same. The default is "balanced".
#' @param diff.otu.mode should be "rare" or "mix" or "abundant". "abundant": differential taxa come from the top quartile of the abundance distribution, "rare": differential OTU come from the bottom quartile of the abundance distribution, and "mix": random set. The default is "abundant".
#' @param covariate.eff.min a number indicating the minimal log2 fold change associated with the condition ("CaseControl" design), or the expected minimal change in the condition for a one-unit change in the taxa ("CrossSectional" design), or the minimal log2 fold change associated with the condition ("MatchedPair" design).
#' @param covariate.eff.maxs a number or a vector indicating the lower and upper range for max log2 fold change. The definition of max log2 fold change: In "CaseControl" design (or "CrossSectional" with binary covariate), it represents the log2 fold change (LFC) between the conditions; In "CrossSectional" desgin with continuous covariate, it represents the expected LFC in response to one-unit change of the condition.
#' @param prev.filter a value between 0 and 1. The prevalence cutoff, defined as the percentage of non-zero values, determines the threshold below which taxa will be filtered out.
#' @param max.abund.filter a value between 0 and 1. The maximum relative abundance threshold determines the point below which taxa will be excluded from the analysis.
#' @param confounder the presence of confounders: "yes" or "no". If you have confounder, power is mostly affected by the correlation between the condition and the confounder, other parameters have much smaller effects and can be set as the default.
#' @param conf.cov.cor a value between 0 and 1, indicating the correlation between the condition and the confounder. A large value indicates stronger correlation. Condition is generated based on: condition= (correlation^2/(1-correlation^2))^0.5 x confounder + N(0,1). Binary condition can be generated by dichotomizing condition using group ratio.
#' @param conf.diff.otu.pct percentage of taxa associated with the confounder and the condition. A numeric value less than percentage of differential taxa associated with the condition. The percentage of taxa affected by the confounder and the condition.
#' @param conf.nondiff.otu.pct percentage of taxa only associated with the confounder. The percentage of taxa affected by the confounder but not the condition.
#' @param confounder.eff.min the minimum log2 fold change of taxa associated with the confounder.
#' @param confounder.eff.max the maximum log2 fold change of taxa associated with the confounder.
#' @param depth.mu the mean sequencing depth to be simulated. The default is 10,000.
#' @param depth.theta the standard deviation of the sequencing depth. It is based on Negative Binomial distribution. It regulates the standard deviation, where higher value results in a reduced standard deviation. Dispersion of sequencing depth = Mean sequencing depth^2 /(Standard deviation^2 - Mean sequencing depth).
#' @return A list with the elements
#' \item{call}{the call}
#' \item{plot}{the power curves}
#' \item{pOCR}{the probability of making at least one correct rejection. Only returns for Taxa-level power.}
#' \item{aTPR}{the average true positive rate. Only returns for Taxa-level power.}
#' \item{power}{Community-level power.}
#' @rdname mPower
#' @examples
#' data(feature.dat)
#' ## Exclude feature exist in less than 2 samples
#' feature.dat <- feature.dat[rowSums(feature.dat != 0) > 2, ]
#' ## Estimate the parameters
#' model.paras <- EstPara(ref.otu.tab = feature.dat)
#' ## Estimate taxa-level power for case control study
#' res1 <- mPower(feature.dat = feature.dat, model.paras = model.paras,
#'               test = 'Community', design = 'CaseControl',
#'               nSams = 50, grp.ratio = 0.5,
#'               iters = 500, alpha = 0.05, distance = 'BC',
#'               diff.otu.pct = 0.1, diff.otu.direct = 'balanced',diff.otu.mode = 'random',
#'               covariate.eff.min = 0, covariate.eff.maxs = c(1, 2, 3),
#'               confounder = 'no', depth.mu = 10000, depth.theta = 5)
#' ## Estimate community-level power for case control study
#' res2 <- mPower(feature.dat = feature.dat, model.paras = model.paras,
#'               test = 'Taxa', design = 'CaseControl',
#'               nSams = c(20, 40, 80), grp.ratio = 0.5,
#'               iters = 100, alpha = 0.05, distance = 'BC',
#'               diff.otu.pct = 0.1, diff.otu.direct = 'balanced',diff.otu.mode = 'random',
#'               covariate.eff.min = 0, covariate.eff.maxs = 2,
#'               prev.filter = 0.1, max.abund.filter = 0.002,
#'               confounder = 'yes', depth.mu = 100000, depth.theta = 5)

#' @author Lu Yang \email{luyang1005@gmail.com} & Jun Chen \email{Chen.Jun2@mayo.edu}
#' @references Lu Yang, Jun Chen. mPower: a Real Data-based Power Analysis Tool for Microbiome Study Design.
#' @import GUniFrac vegan tidyr ggpubr stats ggplot2 dirmult tibble MASS modeest
#' @importFrom reshape melt
#' @export

mPower <- function(feature.dat, model.paras,
                   test = c('Taxa','Community'), design = c('CaseControl','CrossSectional','MatchedPair'),
                   nSams = 50, grp.ratio = 0.5,
                   iters = 50,
                   alpha = 0.05, distance = c('BC','Jaccard'),
                   diff.otu.pct = 0.1, diff.otu.direct = c('unbalanced','balanced'), diff.otu.mode = c('random','abundant','rare'),
                   covariate.eff.min=0, covariate.eff.maxs = c(1,2), prev.filter = 0.1, max.abund.filter = 0.002,
                   confounder = c('no','yes'), conf.cov.cor = 0.6, conf.diff.otu.pct = 0.1, conf.nondiff.otu.pct = 0.1, confounder.eff.min = 0, confounder.eff.max = 1,
                   depth.mu = 10000, depth.theta = 5, verbose =T){

  this.call <- match.call()
  design <- match.arg(design)
  test <- match.arg(test)
  distance <- match.arg(distance)
  diff.otu.mode <- match.arg(diff.otu.mode)
  diff.otu.direct <- match.arg(diff.otu.direct)
  confounder <- match.arg(confounder)
  methods <- 'LinDA' # To be updated as multiple DAA methods

  if (design == 'MatchedPair') {
    grp.name <- 'time'
  } else if (design == "CaseControl") {
    grp.name <- 'X'
    covariate.type <- 'binary'
  } else if (design == "CrossSectional") {
    grp.name <- 'X'
    covariate.type <- 'continuous'
  }

  adj.name <- if (confounder == "yes") "Z" else NULL

  if(verbose) cat('----Calculating in progressing----')

  ## 0. CaseControl or CrossSectional design
  if(design == "CaseControl" || design == "CrossSectional") {

    if(diff.otu.direct=='unbalanced') covariate.eff.min <- 0

    TPR <- FDR <- TPR.top <- TPR.bottom <- FDR.top <- FDR.bottom <- Ps <- R2s <- Probs <- list()
    for(nSam in nSams){
      for(covariate.eff.max in covariate.eff.maxs){

        if(verbose) cat('\n nSam=',nSam,' & covariate.eff.max=',covariate.eff.max,'\n')

        tpr <- fdr <- tpr.top <- fdr.top <- tpr.bottom <- fdr.bottom <- prob <-
          matrix(NA, nrow = iters, ncol = length(methods), dimnames = list(1:iters, methods))
        P <- R2 <- c()
        for(iter in 1:iters){
          if(verbose) cat('mPower is calculating:', iter, 'of', iters,'iterations.\n')
          ## 1. data simulation
          sim.obj <- SimulateMSeqU(
            ref.otu.tab = feature.dat,
            model.paras = model.paras,
            nSam = nSam,
            grp.ratio = grp.ratio,
            nOTU = nrow(feature.dat),
            diff.otu.pct = diff.otu.pct,
            diff.otu.mode = diff.otu.mode,
            diff.otu.direct = diff.otu.direct,
            covariate.type = covariate.type,
            covariate.eff.min = covariate.eff.min,
            covariate.eff.max = covariate.eff.max,
            conf.cov.cor = conf.cov.cor,
            confounder = confounder,
            conf.diff.otu.pct = conf.diff.otu.pct,
            conf.nondiff.otu.pct = conf.nondiff.otu.pct,
            confounder.eff.min = confounder.eff.min,
            confounder.eff.max = confounder.eff.max,
            depth.mu = depth.mu,
            depth.theta = depth.theta
          )

          conf.df <- sim.obj$confounder
          colnames(conf.df) <- 'Z'
          meta.dat <- data.frame(X = sim.obj$covariate, conf.df)
          if(length(unique(meta.dat$X))==2){meta.dat$X <- as.factor(meta.dat$X)}
          truth <- sim.obj$diff.otu.ind
          names(truth) <- sim.obj$otu.names

          ## 2. Taxa-level power
          if(test == 'Taxa'){
            for(method in methods){
              try({
                res.obj <- perform_DAA(feature.dat = sim.obj$otu.tab.sim, meta.dat = meta.dat, design = design,
                                       prev.filter = prev.filter, max.abund.filter = max.abund.filter,
                                       grp.name = grp.name, adj.name = adj.name, method = method, verbose=verbose)
                p.adj.fdr <- res.obj$p.adj.fdr
                names(p.adj.fdr) <- rownames(res.obj)
                truth <- truth[names(p.adj.fdr)]

                top <- names(which(rowMeans(sim.obj$otu.tab.sim) > median(rowMeans(sim.obj$otu.tab.sim))))
                res.top <- cal.tpr.fdr(p.adj.fdr[top], truth=truth[top], cutoff = alpha)
                tpr.top[iter,method] <- unname(res.top["TPR"])
                fdr.top[iter,method] <- unname(res.top["FDR"])

                bottom <- names(which(rowMeans(sim.obj$otu.tab.sim) <= median(rowMeans(sim.obj$otu.tab.sim))))
                res.bottom <- cal.tpr.fdr(p.adj.fdr[bottom], truth=truth[bottom], cutoff = alpha)
                tpr.bottom[iter,method] <- unname(res.bottom["TPR"])
                fdr.bottom[iter,method] <- unname(res.bottom["FDR"])

                res <- cal.tpr.fdr(p.adj.fdr[names(truth)], truth=truth, cutoff = alpha)
                tpr[iter,method] <- unname(res["TPR"])
                fdr[iter,method] <- unname(res["FDR"])
                prob[iter,method] <- sum(p.adj.fdr[names(truth)] < alpha & truth ==T)
              })
            }
          }

          ## 2. Community-level power
          if(test =='Community'){
            otu.tab <- t(sim.obj$otu.tab.sim)
            if(distance=='BC') dist.mat <- vegdist(otu.tab / rowSums(otu.tab))
            if(distance=='Jaccard') dist.mat <- dist(otu.tab, method = 'binary')

            if(is.null(adj.name)){
              formula <- paste0('dist.mat ~',grp.name)
            }else{
              formula <- paste0('dist.mat ~', adj.name,'+',grp.name)
            }

            if(nrow(meta.dat)>50){
              suppressWarnings(suppressMessages({obj.dmanova <- dmanova(as.formula(formula),data = meta.dat)}))
              capture.output({
                r2 <- prmatrix(obj.dmanova$aov.tab)[1,'R2']
              }, file = "/dev/null")
              capture.output({
                p <- prmatrix(obj.dmanova$aov.tab)[1,'Pr(>F)']
              }, file = "/dev/null")
            }else{
              suppressWarnings(suppressMessages({obj.adonis <- adonis(as.formula(formula),data = meta.dat)}))
              capture.output({
                r2 <- prmatrix(obj.adonis$aov.tab)['X', 'R2']
              }, file = "/dev/null")
              capture.output({
                p <- prmatrix(obj.adonis$aov.tab)['X','Pr(>F)']
              }, file = "/dev/null")
            }
            P <- c(P, p)
            R2 <- c(R2, r2)
          }
        }

        ## 3. save results for different conditions
        key <- paste0('nSam', nSam, '-covariate.eff.max', covariate.eff.max)
        if(test == 'Taxa'){
          TPR.top[[key]] <- tpr.top
          FDR.top[[key]] <- fdr.top
          TPR.bottom[[key]] <- tpr.bottom
          FDR.bottom[[key]] <- fdr.bottom
          TPR[[key]] <- tpr
          FDR[[key]] <- fdr
          Probs[[key]] <- mean(prob > 0)
        }

        if(test =='Community'){
          Ps[[key]] <- P
          R2s[[key]] <- R2
        }
      }
    }
    if(test == 'Taxa'){
      # overall power results
      TPR.df <- list_to_df(TPR) %>% separate(col = 'grp', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))
      TPR.df <- data_summary(data =melt(TPR.df,id = c('nSam','covariate.eff.max')), formula = '.~ variable +nSam+covariate.eff.max')
      TPR.df$nSam <- factor(TPR.df$nSam, levels = sort(unique(TPR.df$nSam)))
      TPR.df$covariate.eff.max <- factor(TPR.df$covariate.eff.max, levels = sort(unique(TPR.df$covariate.eff.max)))
      plot1 <- generate_plot3(data = TPR.df, effect.size = 'covariate.eff.max', ylab= 'aTPR')

      # probability of making any discovery
      Probs.df <- cbind.data.frame(unlist(Probs)) %>% mutate(variable =method)
      colnames(Probs.df)[1] <- 'value'
      Probs.df <- Probs.df %>% rownames_to_column('grp') %>% separate(col = 'grp', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))
      Probs.df$nSam <- factor(Probs.df$nSam, levels = sort(unique(Probs.df$nSam)))
      Probs.df$covariate.eff.max <- factor(Probs.df$covariate.eff.max, levels = sort(unique(Probs.df$covariate.eff.max)))
      plot7 <- generate_plot3(data = Probs.df, effect.size = 'covariate.eff.max', ylab= 'pOCR', error.bar = F)
      plot <- ggarrange(plot1, plot7, nrow =1)
      pOCR <- Probs.df %>% dplyr::select(-variable) %>% dplyr::rename(pOCR='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')
      aTPR <- TPR.df %>% dplyr::select(-variable) %>% dplyr::rename(aTPR='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')

    }

    if(test == 'Community'){
      suppressWarnings(suppressMessages({adonis.df <- melt(list_vector2df(Ps)) %>% separate(col = 'variable', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max))) %>%
        mutate(iter = ifelse(value <= alpha, 1,0))}))
      adonis.df$nSam <- factor(adonis.df$nSam, levels = sort(unique(adonis.df$nSam)))
      adonis.df$covariate.eff.max <- factor(adonis.df$covariate.eff.max, levels = sort(unique(adonis.df$covariate.eff.max)))
      TPR.beta <- data_summary(data=adonis.df, 'iter ~ nSam + covariate.eff.max') %>% dplyr::rename(value = 'iter') %>% mutate(variable = 'beta')
      plot5 <- generate_plot3(data = TPR.beta, effect.size = 'covariate.eff.max',ylab= 'Power')

      suppressWarnings(suppressMessages({adonis.R2 <- melt(list_vector2df(R2s)) %>%
        separate(col = 'variable', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))}))
      adonis.R2$nSam <- factor(adonis.R2$nSam, levels = sort(unique(adonis.R2$nSam)))
      adonis.R2$covariate.eff.max <- factor(adonis.R2$covariate.eff.max, levels = sort(unique(adonis.R2$covariate.eff.max)))
      plot9 <- generate_plot3(data = adonis.R2, effect.size = 'covariate.eff.max', ylab= 'R2 (Percent Explained Variance)', R2=T)
      plot <- ggarrange(plot9, plot5, nrow =1)

      power <- TPR.beta %>% dplyr::select(-variable) %>% dplyr::rename(power='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')
    }
  }

  ## 0. MatchedPair design
  if(design == 'MatchedPair') {
    MgT.maxS <- covariate.eff.maxs
    nSubjects <- nSams

    if(diff.otu.direct=='unbalanced') balanced.T = F; MgT.min <- 0 ## set unbalanced with min log2 fold change=0 to create same direction of change
    if(diff.otu.direct=='balanced') balanced.T = T; MgT.min <- covariate.eff.min

    TPR <- FDR <- TPR.top <- TPR.bottom <- FDR.top <- FDR.bottom <- Ps <- R2s <- Probs <- list()
    for(nSubject in nSubjects){
      for(MgT.max in MgT.maxS){

        if(verbose) cat('\n nSubject=',nSubject,'& MgT.max=',MgT.max,'\n')

        tpr <- fdr <- tpr.top <- fdr.top <- tpr.bottom <- fdr.bottom <- prob <-
          matrix(NA, nrow = iters, ncol = length(methods), dimnames = list(1:iters, methods))
        P <- R2 <- c()
        for(iter in 1:iters){
          if(verbose) cat('mPower is calculating:', iter, 'of', iters,' iterations.\n')
          ## 1. data simulation
          sim.obj <- SimulateMSeqCU(ref.otu.tab= feature.dat, model.paras = model.paras,
                                    nSubject = nSubject, nOTU = nrow(feature.dat), nTime = 2,
                                    error.sd = 1, diff.otu.mode = diff.otu.mode,
                                    MgX.min = 0, MgX.max = 1, X.diff.otu.pct = 0, grp.ratio = 1,balanced.X = TRUE,
                                    MgT.min = MgT.min, MgT.max = MgT.max, SbT = 0, T.diff.otu.pct = diff.otu.pct, balanced.T = balanced.T,
                                    MgXT.min = 0, MgXT.max = 0, XT.diff.otu.pct = 0,
                                    confounder = 'none',
                                    MgZ.min = 0, MgZ.max = 0, Z.diff.otu.pct = 0, Z.nondiff.otu.pct = 0,
                                    depth.mu = depth.mu, depth.theta = depth.theta, depth.conf.factor = 0)

          otu.tab.sim <- sim.obj$otu.tab.sim
          meta.dat <- sim.obj$meta
          if(length(unique(meta.dat$time))==2){meta.dat$X <- as.factor(meta.dat$time)}
          meta.dat$SubjectID <- as.factor(meta.dat$SubjectID)
          meta.dat$time <- as.factor(meta.dat$time)
          truth <- sim.obj$T.diff.otu.ind;names(truth) <- sim.obj$otu.names

          ## 2. Taxa-level power
          if(test =='Taxa'){
            for(method in methods){
              res.obj <- perform_DAA(feature.dat = sim.obj$otu.tab.sim, meta.dat = meta.dat, design = design,
                                     grp.name = grp.name, adj.name = NULL,
                                     prev.filter = prev.filter, max.abund.filter = max.abund.filter,
                                     method = method)
              # cat('[----- DAA with ',method,' MatchedPair finished -----]\n')
              p.adj.fdr <- res.obj$p.adj.fdr
              names(p.adj.fdr) <- rownames(res.obj)

              truth <- truth[names(p.adj.fdr)]

              top <- names(which(rowMeans(sim.obj$otu.tab.sim) > median(rowMeans(sim.obj$otu.tab.sim))))
              res.top <- cal.tpr.fdr(p.adj.fdr[top], truth=truth[top], cutoff = alpha)
              tpr.top[iter,method] <- unname(res.top["TPR"])
              fdr.top[iter,method] <- unname(res.top["FDR"])

              bottom <- names(which(rowMeans(sim.obj$otu.tab.sim) <= median(rowMeans(sim.obj$otu.tab.sim))))
              res.bottom <- cal.tpr.fdr(p.adj.fdr[bottom], truth=truth[bottom], cutoff = alpha)
              tpr.bottom[iter,method] <- unname(res.bottom["TPR"])
              fdr.bottom[iter,method] <- unname(res.bottom["FDR"])

              res <- cal.tpr.fdr(p.adj.fdr[names(truth)], truth=truth, cutoff = alpha)
              tpr[iter,method] <- unname(res["TPR"])
              fdr[iter,method] <- unname(res["FDR"])
              prob[iter,method] <- sum(p.adj.fdr[names(truth)] < alpha & truth ==T)
            }
          }

          ## 2. Community-level power
          if(test =='Community'){
            otu.tab <- t(sim.obj$otu.tab.sim)
            if(distance=='BC') dist.mat <- vegdist(otu.tab / rowSums(otu.tab))
            if(distance=='Jaccard') dist.mat <- dist(otu.tab, method = 'binary')

            if(nrow(meta.dat)>50){
              suppressWarnings(suppressMessages({obj.dmanova <- dmanova(dist.mat ~ SubjectID + time,data = meta.dat)}))
              capture.output({
                r2 <- prmatrix(obj.dmanova$aov.tab)[1,'R2']
              }, file = "/dev/null")
              capture.output({
                p <- prmatrix(obj.dmanova$aov.tab)[1,'Pr(>F)']
              }, file = "/dev/null")
            }else{
              suppressWarnings(suppressMessages({obj.dmanova <- with(meta.dat, adonis2(dist.mat ~ time, data = meta.dat, permutations = 99, strata = meta.dat$SubjectID))}))
              capture.output({
                r2 <- prmatrix(obj.dmanova)['time','R2']
              }, file = "/dev/null")
              capture.output({
                p <- prmatrix(obj.dmanova)['time','Pr(>F)']
              }, file = "/dev/null")
            }

            P <- c(P, p)
            R2 <- c(R2, r2)
          }
        }

        ## 3. save results for different conditions
        key <- paste0('nSam',nSubject,'-covariate.eff.max',MgT.max)
        if(test =='Taxa'){
          TPR.top[[key]] <- tpr.top
          FDR.top[[key]] <- fdr.top

          TPR.bottom[[key]] <- tpr.bottom
          FDR.bottom[[key]] <- fdr.bottom

          TPR[[key]] <- tpr
          FDR[[key]] <- fdr

          Probs[[key]] <- mean(prob>0)
        }

        if(test == 'Community'){
          Ps[[key]] <- P
          R2s[[key]] <- R2
        }
      }
    }


    ## 4. Generate power plots
    if(test == 'Taxa'){
      # overall power results
      TPR.df <- list_to_df(TPR) %>% separate(col = 'grp', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))
      TPR.df <- data_summary(data =melt(TPR.df,id = c('nSam','covariate.eff.max')), formula = '.~ variable +nSam+covariate.eff.max')
      TPR.df$nSam <- factor(TPR.df$nSam, levels = sort(unique(TPR.df$nSam)))
      TPR.df$covariate.eff.max <- factor(TPR.df$covariate.eff.max, levels = sort(unique(TPR.df$covariate.eff.max)))
      plot1 <- generate_plot3(data = TPR.df,effect.size = 'covariate.eff.max', ylab= 'aTPR', matched.pair = T, verbose=verbose)

      # probability of making any discovery
      Probs.df <- cbind.data.frame(unlist(Probs)) %>% mutate(variable =method)
      colnames(Probs.df)[1] <- 'value'
      Probs.df <- Probs.df %>% rownames_to_column('grp') %>% separate(col = 'grp', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))
      Probs.df$nSam <- factor(Probs.df$nSam, levels = sort(unique(Probs.df$nSam)))
      Probs.df$covariate.eff.max <- factor(Probs.df$covariate.eff.max, levels = sort(unique(Probs.df$covariate.eff.max)))
      plot7 <- generate_plot3(data = Probs.df, effect.size = 'covariate.eff.max', ylab= 'pOCR', error.bar = F, matched.pair = T)

      plot <- ggarrange(plot1, plot7, nrow =1)

      pOCR <- Probs.df %>% dplyr::select(-variable) %>% dplyr::rename(pOCR='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')
      aTPR <- TPR.df %>% dplyr::select(-variable) %>% dplyr::rename(aTPR='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')
    }

    if(test == 'Community'){
      suppressWarnings(suppressMessages({adonis.df <- melt(list_vector2df(Ps)) %>%
        separate(col = 'variable', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max))) %>%
        mutate(iter = ifelse(value <= alpha, 1,0))}))
      adonis.df$nSam <- factor(adonis.df$nSam, levels = sort(unique(adonis.df$nSam)))
      adonis.df$covariate.eff.max <- factor(adonis.df$covariate.eff.max, levels = sort(unique(adonis.df$covariate.eff.max)))
      TPR.beta <- data_summary(data=adonis.df, 'iter ~ nSam + covariate.eff.max') %>% dplyr::rename(value = 'iter') %>% mutate(variable = 'beta')
      plot5 <- generate_plot3(data = TPR.beta, effect.size = 'covariate.eff.max', ylab= 'Power', matched.pair = T)

      suppressWarnings(suppressMessages({adonis.R2 <- melt(list_vector2df(R2s)) %>%
        separate(col = 'variable', into = c('nSam','covariate.eff.max'), sep = '-') %>%
        mutate(nSam = as.numeric(gsub('nSam','',nSam)), covariate.eff.max=as.numeric(gsub('covariate.eff.max','',covariate.eff.max)))}))
      adonis.R2$nSam <- factor(adonis.R2$nSam, levels = sort(unique(adonis.R2$nSam)))
      adonis.R2$covariate.eff.max <- factor(adonis.R2$covariate.eff.max, levels = sort(unique(adonis.R2$covariate.eff.max)))
      plot9 <- generate_plot3(data = adonis.R2, effect.size = 'covariate.eff.max', ylab= 'R2 (Percent Explained Variance)', R2=T, matched.pair = T)

      plot <- ggarrange(plot9, plot5, nrow =1)
      power <- TPR.beta %>% dplyr::select(-variable) %>% dplyr::rename(power='value', `max log2 fold change` = 'covariate.eff.max', `Sample size`='nSam')
    }
  }

  if(test == 'Community') return(list(call = this.call, plot=plot, power=power))
  if(test == 'Taxa') return(list(call = this.call, plot=plot, pOCR=pOCR, aTPR=aTPR))
}



